# Perceptual Locomotion with Controllable Pace and Natural Gait Transitions Over Uneven Terrain

Codebase supporting CPG-guided locomotion project. 

# Overview

## Resources

A poster describing the underlying theory and ideas can be found in ```docs/cpg_locomotion.pdf```

# Quickstart

## Setup

Our repository works for Python 3.8+. 
Install dependencies and source in developer mode:

```
python -m pip install -e .
```

## Training a New Model

To reproduce the training settings from the poster:

```
python train.py --algo ppo --env A1GymEnv-v0 -f logs --n-timesteps 2000000
```

### Gait Randomization Settings 

The training script trains a policy to execute a variety of gaits. The default randomization settings are: 
- Gait type selected from (walk, trot)
- Gait frequency in the range [1.5, 2.5]
- Gait duty factor in the range [0.5, 0.75]
- Target velocity in the range [0.4, 0.8] m/s

The gait randomization settings can be configured by editing the arguments for `cpg_sensors.ReferenceGaitSensor` in `blind_walking/envs/env_builder.py` 

```
cpg_sensors.ReferenceGaitSensor(
    # Modify gait type here
    gait_names=["walk", "trot"] if gait_name is None else [gait_name],
    # Modify gait frequency here
    gait_frequency_upper=2.5 if gait_frequency is None else gait_frequency,
    gait_frequency_lower=1.5 if gait_frequency is None else gait_frequency,
    # Modify duty factor here
    duty_factor_upper=0.75 if duty_factor is None else duty_factor,
    duty_factor_lower=0.5 if duty_factor is None else duty_factor,
    obs_steps_ahead=[0, 1, 2, 10, 50],
)
```

The target velocity settings can be configured by editing the arguments for 
`environment_sensors.ForwardTargetPositionSensor`.

```
    environment_sensors.ForwardTargetPositionSensor(
        min_range=0.01, 
        max_range=0.02
    ),
```
In the above, `min_range` and `max_range` define the distance of the next target waypoint in the robot's frame of reference. With an environment time step of 0.025s, the effective min velocity is 0.01 / 0.025 = 0.4 m/s. Similarly, the max velocity is 0.02 / 0.025 = 0.8 m/s

## Evaluating a Model 

A pre-trained locomotion policy is provided in `saved_models/policy`.  
To run the policy in Pybullet simulation in headless mode: 

```
python scripts/enjoy_with_logging.py --algo ppo --env A1GymEnv-v0 -f saved_models/policy --no-render
```

The `--record` flag can optionally be added to record the episode as a video. 
Video parameters such as camera angles can be configured in `blind_walking.envs.locomotion_gym_config.SimulationParameters`. 

### Evaluating with a Fixed Gait

Specific gaits can be evaluated by overriding `env_kwargs`

```
    python scripts/enjoy_with_logging.py --algo ppo --env A1GymEnv-v0 -f saved_models/policy --no-render --env-kwargs gait_name:"'trot'" gait_frequency:2.0 duty_factor:0.5
```

The above example overrides the gait parameters and evaluates the policy on a trotting gat with frequency of 2.0 Hz and duty factor of 0.5

### Evaluating with a Gait Transition

By default, the gait is held constant during the evaluation episode of 1000 timesteps. To enable gait transitions, it is necessary to modify the reference gait being generated by the CPG. Examples of gait schedules are given in `blind_walking/envs/sensors/cpg_sensors.py`: 

```
# Schedule a walk from 0 to 200 timesteps, a trot from 200 to 400 timesteps, and a walk from 400 to 1000 timesteps
gait_name_schedule = lambda t : "walk" if t < 200 or t > 400  else "trot"
gait_freq_schedule = lambda t: 1.0 if t < 200 or t > 400 else 3.0
duty_factor_schedule = lambda t : 0.75 if t < 200 or t > 400 else 0.5
```

Gait scheduling is enabled by uncommenting the corresponding lines in `cpg_sensors.ReferenceGaitSensor.on_step`: 

```
# Uncomment below to turn on gait type scheduling
# self.set_gait_name(gait_name_schedule(t))
# Uncomment below to turn on duty factor scheduling
# self.set_duty_factor(duty_factor_schedule(t))
# Uncomment below toturn on gait frequency scheduling
# self.set_period(1/gait_freq_schedule(t))
```


# Acknowledgements

This codebase draws inspiration from the following codebases: 
- [Stable Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)
- [Motion Imitation](https://github.com/erwincoumans/motion_imitation)

## Contact

For any questions regarding the ideas, implementation, or code, feel free to contact Daniel Tan at dtch009@gmail.com